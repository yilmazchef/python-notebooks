{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Installations\n",
    "\n",
    "The installation process for this project is a bit more than usual. First we have to download a C++ compiler. We can do this by installing Visual Studios. You can download the community version for free from their website. Once the installer we will run it and select the ‘Desktop development with C++’. The download and installation will take some time as it is a few Gbs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After completing and restarting the computer, now we will head on to our Pycharm project. Here we will install the required packages. Below is the list.\n",
    "\n",
    "- cmake\n",
    "- dlib\n",
    "- face_recognition\n",
    "- numpy\n",
    "- opencv-python"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Understanding the problem\n",
    "\n",
    "Although many face recognition algorithms have been developed over the years, their speed and accuracy balance has not been quiet optimal . But some recent advancements have shown promise. A good example is Facebook, where they are able to tag you and your friends with just a few images of training and with accuracy as high as 98%. So how does this work . Today we will try to replicate similar results using a face recognition library developed by Adam Geitgey. Lets look at the 4 problems he explained in his article.\n",
    "\n",
    "Face recognition is a series of several problems:\n",
    "\n",
    "- First, look at a picture and find all the faces in it\n",
    "- Second, focus on each face and be able to understand that even if a face is turned in a weird direction or in bad lighting, it is still the same person.\n",
    "- Third, be able to pick out unique features of the face that you can use to tell it apart from other people— like how big the eyes are, how long the face is, etc.\n",
    "- Finally, compare the unique features of that face to all the people you already know to determine the person’s name."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find faces in pictures\n",
    "\n",
    "We start by loading an example picture using Python imaging library. Go ahead and **run the cell bellow** to see the image."
   ],
   "metadata": {
    "cell_id": "00000-998f75df-7d41-471f-bb87-9d255cdcebb4"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00001-543e8415-0801-4538-a669-2eae5e7989ce"
   },
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "\n",
    "# The program we will be finding faces on the example below\n",
    "pil_im = Image.open('face/two_people.jpg')\n",
    "display(pil_im)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Learning from example\n",
    "Now we show the library two different faces ([Joe Biden](/biden.jpg), [Barack Obama](/obama.jpg)) and generate the encodings for them. Encoding is simply a low dimensional representation of a face that can be easily compared with other faces the library will recognize in the future."
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00002-c945e00f-7a65-4bac-a161-e57cf141908e"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00003-7815290b-9024-4316-bc09-b66254e39bee"
   },
   "source": [
    "import face_recognition\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "\n",
    "# This is an example of running face recognition on a single image\n",
    "# and drawing a box around each person that was identified.\n",
    "\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "obama_image = face_recognition.load_image_file(\"face/obama.jpg\")\n",
    "obama_face_encoding = face_recognition.face_encodings(obama_image)[0]\n",
    "\n",
    "# Load a second sample picture and learn how to recognize it.\n",
    "biden_image = face_recognition.load_image_file(\"face/biden.jpg\")\n",
    "biden_face_encoding = face_recognition.face_encodings(biden_image)[0]\n",
    "\n",
    "# Create arrays of known face encodings and their names\n",
    "known_face_encodings = [\n",
    "    obama_face_encoding,\n",
    "    biden_face_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Barack Obama\",\n",
    "    \"Joe Biden\"\n",
    "]\n",
    "print('Learned encoding for', len(known_face_encodings), 'images.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Showtime\nFinally, we load the image we looked at in the first cell, find the faces in the image and compare them with the encodings the library generated in the previous step. We can see that library now correctly recognizes Barack and Joe in the input.",
   "metadata": {
    "tags": [],
    "cell_id": "00004-45f19551-060f-49fe-963d-36c897f0ff0c"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00005-2181a8f1-f1d8-43db-9037-9388940f548a"
   },
   "source": "# Load an image with an unknown face\nunknown_image = face_recognition.load_image_file(\"two_people.jpg\")\n\n# Find all the faces and face encodings in the unknown image\nface_locations = face_recognition.face_locations(unknown_image)\nface_encodings = face_recognition.face_encodings(unknown_image, face_locations)\n\n# Convert the image to a PIL-format image so that we can draw on top of it with the Pillow library\n# See http://pillow.readthedocs.io/ for more about PIL/Pillow\npil_image = Image.fromarray(unknown_image)\n# Create a Pillow ImageDraw Draw instance to draw with\ndraw = ImageDraw.Draw(pil_image)\n\n# Loop through each face found in the unknown image\nfor (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n    # See if the face is a match for the known face(s)\n    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n\n    name = \"Unknown\"\n\n    # Or instead, use the known face with the smallest distance to the new face\n    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n    best_match_index = np.argmin(face_distances)\n    if matches[best_match_index]:\n        name = known_face_names[best_match_index]\n\n    # Draw a box around the face using the Pillow module\n    draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n\n    # Draw a label with a name below the face\n    text_width, text_height = draw.textsize(name)\n    draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n    draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n\n\n# Remove the drawing library from memory as per the Pillow docs\ndel draw\n\n# Display the resulting image\ndisplay(pil_image)",
   "execution_count": null,
   "outputs": []
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "deepnoteSessionId": "8b3c3451-4353-4ef0-acbf-97ffca907435",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "deepnote_notebook_id": "81cc4083-caae-45b2-894e-bb0bbf406d50",
  "deepnote_execution_queue": []
 }
}