{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d107ef",
   "metadata": {},
   "source": [
    "(wrkflow-environments)=\n",
    "# Virtual Code Environments\n",
    "\n",
    "In this chapter, you're going to learn about virtual coding environments. These allow you to isolate all of the packages that you're using to do analysis for one project from the set of packages you might need for a different project. They're an important part of creating a reproducible analytical pipeline (more on that in {ref}`wrkflow-rap` but a key benefit is that others can reproduce the environment you used) and it's best practice to have an isolated environment per project.\n",
    "\n",
    "It may be easier to illustrate creating separate environments with an example. Let's say you're using Python 3.8, statsmodels, and pandas for one project, project A. And, for project B, you're using Python 3.9 with numpy and scikit-learn. Even with the same version of Python, best practice would be to have two separate virtual Python environments: environment A, with everything needed for project A, and environment B, with everything needed for project B. For the case where you're using different versions of Python, this isn't just best practice, it's essential.\n",
    "\n",
    "Many programming languages now come with an option to install packages and a version of the language in isolated enironments. In Python, there are multiple tools for managing different environments. Of those, the easiest to work with is probably [**Anaconda**](https://docs.conda.io/projects/conda/en/latest/index.html) (conda for short), though [**poetry**](https://python-poetry.org/) is another strong option.\n",
    "\n",
    "If you're just getting going with coding, this book recommends that you use Anaconda (aka conda) environments.\n",
    "\n",
    "## Using Anaconda to Manage Python Environments\n",
    "\n",
    "Much of these two subsections is covered by the Anaconda documentation on [managing virtual environments](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html).\n",
    "\n",
    "### Creating Environments\n",
    "\n",
    "If you're using Anaconda, you manage and change environments on the command line (more on the command line in {ref}`wrkflow-command-line`). Before following these instructions, check that you have Anaconda installed and activated. You should see something like `(base) username@computername:~$` on the command line (base is the default conda environment).\n",
    "\n",
    "To create a new environment called \"myenv\" with a specific version of Python (but no extra packages installed), it's\n",
    "\n",
    "```bash\n",
    "conda create -n myenv python=3.8\n",
    "```\n",
    "\n",
    "where you can of course specify other versions of Python by changing the number. To throw in a package or two, just add them to the end, for example\n",
    "\n",
    "```bash\n",
    "conda create -n myenv python=3.8 pandas jupyter\n",
    "```\n",
    "\n",
    "You can see a list of the currently installed environments by running\n",
    "\n",
    "```bash\n",
    "conda env list\n",
    "```\n",
    "\n",
    "Running the same command within an environment will \n",
    "\n",
    "When you install Anaconda, you will begin with a \"base\" environment. It's a good idea not to use this for projects but to instead to create a new environment for each project.\n",
    "\n",
    "There are two downsides to installing environments directly from the command line. One is that you may have lots of packages. The second is that you may wish to keep a record of the environment you created. For both of these reasons, you can specify a conda environment using a file.\n",
    "\n",
    "The pandas example we saw above would look like\n",
    "\n",
    "```yaml\n",
    "name: myenv\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.8\n",
    "  - pandas\n",
    "  - jupyter\n",
    "\n",
    "```\n",
    "\n",
    "The environment is given by `name`, the channel (where to look for the packages) by `channels`, the specific packages by `dependencies`. Not all packages are available on conda's channels, so sometimes extra ones are needed. And some packages are only available on pip; these can be specified with a sub-section of the file like so for the **skimpy** package:\n",
    "\n",
    "```yaml\n",
    "name: myenv\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.8\n",
    "  - pandas\n",
    "  - jupyter\n",
    "  - pip:\n",
    "    - skimpy\n",
    "\n",
    "```\n",
    "\n",
    "This goes into a file called `environment.yml`, which can be installed by running\n",
    "\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "```\n",
    "\n",
    "This book is put together using an isolated *conda* environment specificied in a file. It's an unusually big one because there are a lot of packages featured in the book! Here they are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d62aaa8",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">name: codeforecon\n",
       "channels:\n",
       "  - conda-forge\n",
       "  - fastai\n",
       "dependencies:\n",
       "  - jupyter\n",
       "  - numpy\n",
       "  - pandas\n",
       "  - pip\n",
       "  - <span style=\"color: #808000; text-decoration-color: #808000\">python</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.8</span>\n",
       "  - pyyaml\n",
       "  - scipy\n",
       "  - seaborn\n",
       "  - statsmodels\n",
       "  - tqdm\n",
       "  - yaml\n",
       "  - pycodestyle\n",
       "  - pyarrow\n",
       "  - geopandas\n",
       "  - autopep8\n",
       "  - geoplot\n",
       "  - nltk\n",
       "  - arrow\n",
       "  - osmnx\n",
       "  - pandas-datareader\n",
       "  - pandasdmx\n",
       "  - pdfminer.six\n",
       "  - jupyter-book\n",
       "  - pytest\n",
       "  - rich\n",
       "  - pyinstrument\n",
       "  - loguru\n",
       "  - pre-commit\n",
       "  - pandera\n",
       "  - linearmodels\n",
       "  - sympy\n",
       "  - pingouin\n",
       "  - jax\n",
       "  - plotly\n",
       "  - spacy\n",
       "  - pandas-profiling\n",
       "  - plotnine\n",
       "  - altair\n",
       "  - datatable\n",
       "  - cerberus\n",
       "  - great-expectations\n",
       "  - dagster\n",
       "  - icecream\n",
       "  - waterfallcharts\n",
       "  - matplotlib-venn\n",
       "  - pywaffle\n",
       "  - joypy\n",
       "  - jupyterlab\n",
       "  - textstat\n",
       "  - nbstripout\n",
       "  - vega_datasets\n",
       "  - ghp-import\n",
       "  - colorcet\n",
       "  - holoviews\n",
       "  - requests-cache\n",
       "  - pip\n",
       "  - fastcore\n",
       "  - arch-py\n",
       "  - workalendar\n",
       "  - wordcloud\n",
       "  - pymc3\n",
       "  - theano-pymc\n",
       "  - mkl\n",
       "  - mkl-service\n",
       "  - bambi\n",
       "  - pdftotext\n",
       "  - bottleneck\n",
       "  - pip:\n",
       "    - specification_curve\n",
       "    - twopiece\n",
       "    - stargazer\n",
       "    - matplotlib-scalebar\n",
       "    - black-nb\n",
       "    - pyhdfe\n",
       "    - skimpy\n",
       "    - dataprep\n",
       "    - graphviz\n",
       "    - ruptures\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "name: codeforecon\n",
       "channels:\n",
       "  - conda-forge\n",
       "  - fastai\n",
       "dependencies:\n",
       "  - jupyter\n",
       "  - numpy\n",
       "  - pandas\n",
       "  - pip\n",
       "  - \u001b[33mpython\u001b[0m=\u001b[1;36m3\u001b[0m\u001b[1;36m.8\u001b[0m\n",
       "  - pyyaml\n",
       "  - scipy\n",
       "  - seaborn\n",
       "  - statsmodels\n",
       "  - tqdm\n",
       "  - yaml\n",
       "  - pycodestyle\n",
       "  - pyarrow\n",
       "  - geopandas\n",
       "  - autopep8\n",
       "  - geoplot\n",
       "  - nltk\n",
       "  - arrow\n",
       "  - osmnx\n",
       "  - pandas-datareader\n",
       "  - pandasdmx\n",
       "  - pdfminer.six\n",
       "  - jupyter-book\n",
       "  - pytest\n",
       "  - rich\n",
       "  - pyinstrument\n",
       "  - loguru\n",
       "  - pre-commit\n",
       "  - pandera\n",
       "  - linearmodels\n",
       "  - sympy\n",
       "  - pingouin\n",
       "  - jax\n",
       "  - plotly\n",
       "  - spacy\n",
       "  - pandas-profiling\n",
       "  - plotnine\n",
       "  - altair\n",
       "  - datatable\n",
       "  - cerberus\n",
       "  - great-expectations\n",
       "  - dagster\n",
       "  - icecream\n",
       "  - waterfallcharts\n",
       "  - matplotlib-venn\n",
       "  - pywaffle\n",
       "  - joypy\n",
       "  - jupyterlab\n",
       "  - textstat\n",
       "  - nbstripout\n",
       "  - vega_datasets\n",
       "  - ghp-import\n",
       "  - colorcet\n",
       "  - holoviews\n",
       "  - requests-cache\n",
       "  - pip\n",
       "  - fastcore\n",
       "  - arch-py\n",
       "  - workalendar\n",
       "  - wordcloud\n",
       "  - pymc3\n",
       "  - theano-pymc\n",
       "  - mkl\n",
       "  - mkl-service\n",
       "  - bambi\n",
       "  - pdftotext\n",
       "  - bottleneck\n",
       "  - pip:\n",
       "    - specification_curve\n",
       "    - twopiece\n",
       "    - stargazer\n",
       "    - matplotlib-scalebar\n",
       "    - black-nb\n",
       "    - pyhdfe\n",
       "    - skimpy\n",
       "    - dataprep\n",
       "    - graphviz\n",
       "    - ruptures\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "\n",
    "with open(\"environment.yml\", 'r') as stream:\n",
    "    data_loaded = stream.read()\n",
    "\n",
    "print(data_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6261afbe",
   "metadata": {},
   "source": [
    "Of course, you can install packages as you go too, you don't have to specify them when you create the environment. With the relevant environment activated, use `conda install packagename` to do this.\n",
    "\n",
    "Finally, to remove an environment, it's\n",
    "\n",
    "```bash\n",
    "conda remove --name myenv --all\n",
    "```\n",
    "\n",
    "### Using and Switching Between Conda Environments \n",
    "\n",
    "To switch between conda environments on the command line, for example from the base environment to an environment called \"myenv\", use\n",
    "\n",
    "```bash\n",
    "conda activate myenv\n",
    "```\n",
    "\n",
    "on the command line. However, this only switches the environment if you plan to run code on the command line!\n",
    "\n",
    "Fortunately, Visual Studio Code has you covered and makes it very easy to switch Python environments for a project at the click of a button.\n",
    "\n",
    "![A typical user view in Visual Studio Code](https://github.com/aeturrell/coding-for-economists/blob/main/img/vscode_layout.png?raw=true)\n",
    "\n",
    "In the screenshot above, you can see the project-environment in two places: on the blue bar at the bottom of the screen, and (in 5), at the top right hand side of the interactive window. Click on either to change the Python environment that will be used to execute code. A similar top right selector is present for Jupyter Notebooks too.\n",
    "\n",
    "## Using Poetry to Manage Environments\n",
    "\n",
    "[**Poetry**](https://python-poetry.org/) takes a different tack to Anaconda, and one that is built around creating Python packages. So it's more suited to intermediate to advanced coders. As well as providing virtual environments, it can:\n",
    "- creates virtual environments on a per project basis\n",
    "- manage Python package dependencies, and logs them automatically\n",
    "- manage Python package versions, and logs them automatically\n",
    "- install all needed dependencies and packages from previously auto-generated (by Poetry) lists of versions\n",
    "- (advanced) build Python packages\n",
    "- (advanced) upload Python packages to PyPI where they can be installed (ie make your project pip installable by anyone in the world)\n",
    "\n",
    "Just like conda, poetry is a command line tool. But *unlike* conda, the environment it creates is tied to your project folder. After navigating to your project folder on the command line, use\n",
    "\n",
    "```bash\n",
    "poetry init\n",
    "```\n",
    "\n",
    "This will prompt you with a series of questions about the basic packages and version of Python you want to use for your project and will create a (human-readable) `pyproject.toml` file that lists the packages needed for your project. It will also create a virtual Python environment just for your project.\n",
    "\n",
    "To add and install packages, the command is `poetry add package-name`. As you add packages, you will see that the `pyproject.toml` file automatically becomes populated with what you installed. Here's an excerpt of a typical `pyproject.toml` file designed for reproducibility:\n",
    "\n",
    "```text\n",
    "[tool.poetry.dependencies]\n",
    "python = \"3.7.1\"\n",
    "click = \"8.0.1\"\n",
    "rich = \"10.9.0\"\n",
    "pandas = \"1.3.2\"\n",
    "Pygments = \"2.10.0\"\n",
    "typeguard = \"2.12.1\"\n",
    "```\n",
    "\n",
    "The first line here says that this runs on Python 3.7.1. A second file, `poetry.lock`, is also created. This \"locks\" down the dependencies of your packages.\n",
    "\n",
    "### Using Poetry Environments \n",
    "\n",
    "To use the virtual environment to run scripts or tools installed using `poetry add`, you will need to use `poetry run command-name` rather than the usual `command-name`. For example, if you have a script `analysis.py`, you would call it with `poetry run python analysis.py`. You can also open a command line within the virtual environment using `poetry shell`.\n",
    "\n",
    "Visual Studio Code makes this easier though: just as with conda environments, you can set your interactive window or jupyter notebooks to execute with a specific poetry environment.\n",
    "\n",
    "Poetry is especially strong for reproducibility. Imagine you wish to have a co-author or colleague install everything they need for the project. If you send them the automatically generated `pyproject.toml` and `poetry.lock` files then all they need is to have the right version of Python installed already, to navigate to the project folder in the command line, and then to use `poetry install`. This will install all of the packages needed to run the code!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": "0.8",
    "jupytext_version": "1.5.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('codeforecon': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "source_map": [
   14,
   94,
   102
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}